# Project Rule

This file provides guidance to LLM when working with code in this repository.

## Project Overview

iDO is an AI-powered desktop activity monitoring and task recommendation system built with Tauri 2.x. It uses a **three-layer architecture** (Perception → Processing → Consumption) to capture user activities, analyze them with LLM, and provide intelligent task recommendations. All processing happens locally for privacy.

**Tech Stack:**
- Frontend: React 19 + TypeScript 5 + Vite 6 + Tailwind CSS 4
- Backend: Python 3.14+ (PyTauri 0.8 for Tauri integration, FastAPI for development)
- Desktop: Tauri 2.x (Rust runtime)
- Database: SQLite (local)
- State: Zustand 5

## Development Commands

### Environment Setup

```bash
# Initial setup (macOS/Linux)
pnpm setup

# Initial setup (Windows)
pnpm setup:win

# Or manual setup
pnpm setup-all  # Installs frontend + backend dependencies
```

### Development

```bash
# Frontend only (React dev server at localhost:5173)
pnpm dev

# Full app with TypeScript client auto-generation (recommended)
pnpm tauri:dev:gen-ts

# Basic Tauri dev (no TS generation)
pnpm tauri dev

# Backend API server only (FastAPI at localhost:8000)
uvicorn app:app --reload
# or
uv run python app.py
```

### Code Quality

```bash
# Format code
pnpm format

# Check formatting
pnpm lint

# Validate i18n translations consistency
pnpm check-i18n

# Python type checking (ty / basedpyright)
uv run ty check

# Frontend TypeScript compilation check
pnpm tsc
```

> **Type checking requirements**
>
> - **Backend:** Always run `uv run ty check` before submitting backend changes.
>   - Prefer precise type hints (Protocols, `TypedDict`, etc.) over `Any`.
>   - Keep optional dependencies behind `import_module` guards so ty can resolve them.
>   - When ty reports "possibly-missing-attribute", either add a Protocol or guard the access; do not ignore the warning.
>
> - **Frontend:** Always run `pnpm tsc` before submitting frontend changes.
>   - Ensure all TypeScript files compile without errors.
>   - Fix all type errors before committing code.
>   - Do not use `@ts-ignore` or `any` types without justification.

### Tailwind CSS Class Organization

This project uses **Prettier with `prettier-plugin-tailwindcss`** to automatically sort and organize Tailwind CSS classes.

**The `pnpm format` command automatically:**
- Sorts Tailwind classes according to recommended order
- Groups related utilities together
- Ensures consistent class ordering across the codebase

**Guidelines when writing Tailwind classes:**

```typescript
// ❌ Don't: Classes are unsorted and inconsistent
<div className="p-4 text-white bg-blue-500 rounded-lg shadow-md font-bold mb-2 hover:bg-blue-600">

// ✅ Do: Proper Tailwind class organization (auto-formatted)
<div className="mb-2 rounded-lg bg-blue-500 p-4 font-bold shadow-md hover:bg-blue-600">
  {/* Classes are organized by: spacing, sizing, colors, effects, states */}
</div>
```

**Class order (automatically applied by prettier-plugin-tailwindcss):**
1. Layout & positioning (display, position, flex, grid, etc.)
2. Sizing (width, height, etc.)
3. Spacing (margin, padding, gap, etc.)
4. Typography (font-size, font-weight, text-align, etc.)
5. Background & borders (bg-*, border-*, etc.)
6. Shadows & effects (shadow-*, opacity-*, etc.)
7. Hover, focus, active states

**Best practices:**
- Always use the single-class approach: `className="space-y-4"` instead of `className="space-y-2 space-y-4"`
- **Use canonical Tailwind classes instead of arbitrary values when available:**
  - ❌ `aspect-[16/9]` → ✅ `aspect-video`
  - ❌ `w-[456px]` → ✅ Use standard sizes like `w-full`, `w-96`, etc.
  - ❌ `rounded-[8px]` → ✅ Use `rounded-lg`, `rounded-xl`, etc.
  - Arbitrary values should only be used when no canonical class exists
- Prefer semantic component classes over inline utilities for complex components
- Use `clsx` or `tailwind-merge` for conditional classes:

```typescript
import { clsx } from 'clsx'
import { twMerge } from 'tailwind-merge'

// With clsx for simple conditions
<button className={clsx('px-4 py-2', disabled && 'opacity-50 cursor-not-allowed')} />

// With tailwind-merge for overriding conflicting classes
const buttonClass = twMerge('px-4 py-2 bg-blue-500', isSmall && 'px-2 py-1')
```

**Pre-commit verification:**
The `pnpm lint` check (run automatically by pre-commit hooks) will catch any classes that don't follow the proper Tailwind ordering. Always run `pnpm format` before committing to ensure all classes are properly organized.

### Build

```bash
# Production build
pnpm tauri build

# macOS with code signing
pnpm tauri:build:signed

# Platform-specific bundle
pnpm bundle        # macOS/Linux
pnpm bundle:win    # Windows

# Clean build artifacts
pnpm clean
```

### Application Icons

Application icons are stored in `src-tauri/icons/` and configured in `src-tauri/tauri.conf.json`.

**Icon directory structure:**
- `icons/32x32.png`, `icons/64x64.png`, `icons/128x128.png` - Desktop launchers
- `icons/128x128@2x.png` - High-DPI desktop launcher
- `icons/icon.png` - General application icon (512x512)
- `icons/icon.icns` - macOS icon bundle
- `icons/icon.ico` - Windows icon
- `icons/Square*.png` - Windows Start Menu tiles
- `icons/android/` - Android launcher icons (multiple DPIs)
- `icons/ios/` - iOS app icons (multiple sizes)

**When updating application icons:**

1. Replace the source icon files in `src-tauri/icons/`
2. Ensure all required resolutions are present:
   - Minimum: 32x32, 128x128, 128x128@2x, icon.icns, icon.ico
   - Recommended: Also include 64x64, icon.png, and platform-specific icons
3. The `src-tauri/tauri.conf.json` already includes all standard icon references in the `bundle.icon` array
4. For platform-specific builds:
   - **macOS**: Uses `icon.icns` (automatically included)
   - **Windows**: Uses `icon.ico` and Square*.png files for Start Menu tiles
   - **Linux**: Uses `icon.png`
   - **Android**: Uses icons in `android/` directory
   - **iOS**: Uses icons in `ios/` directory

**Icon configuration in tauri.conf.json:**
```json
"bundle": {
  "icon": [
    "icons/32x32.png",
    "icons/64x64.png",
    "icons/128x128.png",
    "icons/128x128@2x.png",
    "icons/icon.icns",
    "icons/icon.ico",
    "icons/icon.png"
  ]
}
```

The bundle will automatically use the appropriate icons for each platform during build.

## Architecture Overview

### Three-Layer Design

```
+------------------------------------------+
|   Consumption Layer                      |
|   AI analysis -> Task recommendations    |
|   * frontend views, agents               |
+------------------------------------------+
              ^
+------------------------------------------+
|   Processing Layer                       |
|   Event filtering -> LLM summary ->      |
|   Activity merging -> DB persistence     |
|   * backend/processing, backend/llm      |
+------------------------------------------+
              ^
+------------------------------------------+
|   Perception Layer                       |
|   Keyboard -> Mouse -> Screenshots       |
|   * backend/perception                   |
+------------------------------------------+
```

**Data Flow:** RawRecords (60s in-memory) → Events (with LLM) → Activities (aggregated every 10min) → Tasks (AI-generated)

### Processing Pipeline & Timing

⚠️ **Critical Timing Information:** Activities take **10-20 minutes** to appear in the UI after user activity starts. This is by design due to the aggregation strategy.

**Key Intervals:**
- **Perception layer:** Screenshots captured every **0.2 seconds** (5 per second per monitor)
- **Main processing loop:** Runs every **30 seconds** (configurable via `monitoring.processing_interval`)
  - First iteration: 100ms (fast startup)
  - Subsequent: 30s interval
- **Event extraction trigger:** When **20+ screenshots accumulated** (~4 seconds of normal usage)
- **Activity aggregation task:** Runs every **10 minutes** (600s, configurable via `processing.activity_summary_interval`)
- **Knowledge/Todo merge:** Runs every **20 minutes** (1200s, configurable via `processing.knowledge_merge_interval`/`todo_merge_interval`)

**Processing happens in three independent asyncio tasks:**
1. Main loop: Filters raw records → accumulates screenshots → calls LLM when threshold reached
2. Activity summary: Aggregates events into activities (10-minute cycle)
3. Knowledge/Todo merge: Combines related knowledge and todos (20-minute cycle)

### Core Backend Components

**Coordinator** (`backend/core/coordinator.py`):
- Orchestrates PerceptionManager and ProcessingPipeline lifecycle
- Manages system state: running | stopped | requires_model | error | starting
- Runs the main `_processing_loop()` every 30 seconds (not 10s)
- Tracks active LLM model and statistics

**API Handler System** (`backend/handlers/__init__.py`):
- `@api_handler` decorator: Write once, works in both PyTauri (desktop) and FastAPI (web)
- Auto-generates TypeScript clients with full type safety
- Auto-converts Python snake_case <-> JavaScript camelCase

**Event System** (`backend/core/events.py`):
- Backend emits Tauri events for certain operations
- **Important:** Events emitted are: `activity-deleted`, `event-deleted`, `activity-updated`, `agent-task-update`, `chat-message-chunk`, `bulk-update-completed`, `monitors-changed`
- **Not emitted:** `activity-created`, `event-created`, `knowledge-created`, `todo-created`
- Activities are synced via **polling-based incremental updates** (every 30s from frontend), not event-driven
- Frontend listens via `useTauriEvents` hook for real-time updates on delete/edit operations

### Frontend Organization

**Views** (`src/views/`):
- Page-level components (Dashboard, Chat, Agents, Activity, Settings, etc.)
- Connected to Zustand stores

**Stores** (`src/lib/stores/`):
- `activity.ts`: Timeline data, incremental updates (uses polling, not events)
- `agents.ts`: Task management
- `chat.ts`: AI chat interface
- `models.ts`: LLM model management
- `settings.ts`: User preferences
- `permissions.ts`: System permissions state

**Auto-generated Client** (`src/lib/client/`):
- TypeScript types and API client auto-generated from Python @api_handler functions
- Regenerated on `pnpm tauri:dev:gen-ts` or `pnpm setup-backend`

### Frontend-Backend Synchronization

Activities are **not** pushed to the frontend via events. Instead, the frontend uses **polling-based incremental updates:**

```typescript
// Frontend polls for activity updates every 30 seconds
setInterval(async () => {
  const updates = await apiClient.getIncrementalActivities({
    sinceVersion: lastVersion
  })
  activityStore.mergeActivities(updates)
}, 30000)
```

**Why?** Activities are created by separate scheduled tasks (10-minute cycle) that aggregate events. Real-time event emission for every new activity would be inefficient. Instead, the frontend periodically syncs the current state.

## Key Development Patterns

### Adding a New API Handler

```python
# backend/handlers/my_feature.py
from backend.handlers import api_handler
from backend.models.base import BaseModel

class MyRequest(BaseModel):
    user_input: str  # Python snake_case

@api_handler(
    body=MyRequest,
    method="POST",
    path="/my-endpoint",
    tags=["my-module"]
)
async def my_handler(body: MyRequest) -> dict:
    """My feature description"""
    return {"success": True, "data": body.user_input}
```

**Auto-registers as:**
- PyTauri command: `apiClient.myHandler({ userInput: "..." })`
- FastAPI endpoint: `POST /api/my-endpoint`

**Important:** After adding handlers:
1. Import in `backend/handlers/__init__.py`
2. Run `pnpm setup-backend` to sync
3. TypeScript types auto-generate in `src/lib/client/`

### Adding a New Agent

```python
# backend/agents/my_agent.py
from backend.agents.base import BaseAgent

class MyAgent(BaseAgent):
    async def can_handle(self, activity: Activity) -> bool:
        # Determine if this agent should process the activity
        return "coding" in activity.description.lower()

    async def execute(self, activity: Activity) -> Task:
        # Generate task recommendations
        return Task(title="...", description="...")

# Register in backend/agents/__init__.py
from .my_agent import MyAgent
AgentFactory.register(MyAgent())
```

### Adding i18n Translations

```typescript
// src/locales/en.ts
export const en = {
  myFeature: {
    title: "My Feature",
    description: "Feature description"
  }
}

// src/locales/zh-CN.ts
export const zhCN = {
  myFeature: {
    title: "My Feature Title in Chinese",
    description: "Feature description in Chinese"
  }
}

// Use in components
import { useTranslation } from 'react-i18next'
const { t } = useTranslation()
t('myFeature.title')
```

**Validate:** Run `pnpm check-i18n` to ensure all keys match across locales.

### Backend Module Import Pattern

The codebase supports both development and production environments:

```python
# Development: imports from backend/ in project root
# Production: imports from ido_backend/ (installed package)

# This is handled automatically in src-tauri/python/ido_app/__init__.py
# Always use: from backend.X import Y (not ido_backend)
```

When adding new Python modules to `backend/`, always run `pnpm setup-backend` to sync.

### TypeScript Client Generation

TypeScript types auto-generate when:
- Running `pnpm tauri:dev:gen-ts`
- Running `pnpm setup-backend`
- Environment variable `PYTAURI_GEN_TS=1` is set

**How it works:**
1. PyTauri analyzes Python @api_handler functions
2. Extracts Pydantic models and type hints
3. Runs `pnpm json2ts` to generate TypeScript interfaces
4. Outputs to `src/lib/client/`

### Emitting Events from Backend

```python
from backend.core.events import emit_event

# Emit event to frontend (use sparingly - only for immediate user feedback)
await emit_event("activity-updated", {"id": activity.id, "version": activity.version})
```

**Note:** Not all data changes emit events. Activities created during aggregation tasks do NOT emit events; they are discovered via polling. Events are primarily used for delete operations and user-triggered edits.

```typescript
// Frontend: Listen to events
import { useTauriEvents } from '@/hooks/useTauriEvents'

useTauriEvents({
  'activity-updated': (payload) => {
    // Handle update
  },
  'activity-deleted': (payload) => {
    // Handle deletion
  }
})
```

### SQL Query Management

**All SQL queries must be placed in `backend/core/sqls/queries.py` for maintainability.**

```python
# backend/core/sqls/queries.py
SELECT_ACTIVITY_COUNT_BY_DATE = """
    SELECT
        DATE(start_time) as date,
        COUNT(*) as count
    FROM activities
    WHERE deleted = 0
    GROUP BY DATE(start_time)
    ORDER BY date DESC
"""

# backend/processing/persistence.py or backend/core/db.py
from core.sqls import queries

async def get_activity_count_by_date(self) -> List[Dict[str, Any]]:
    with self._get_conn() as conn:
        cursor = conn.execute(queries.SELECT_ACTIVITY_COUNT_BY_DATE)
        return [{"date": row["date"], "count": row["count"]} for row in cursor.fetchall()]
```

**Never inline SQL queries in persistence or handler methods.** This pattern:
- Centralizes all SQL for easy review and modification
- Makes schema changes easier to track
- Improves code organization and maintainability

### Database Development Guidelines

- **Use the repository layer.** When adding a table or new CRUD logic, create/update the corresponding repository in `backend/core/db/` and expose the interface through `core/protocols.py`. Handlers and services should depend on these protocols, never on raw SQLite connections.
- **Keep schema + queries in sync.** Update `backend/core/sqls/schema.py` when introducing new tables/columns and add the required `CREATE INDEX` statements at the same time. Every SQL statement (SELECT/INSERT/UPDATE/DELETE) must live in `backend/core/sqls/queries.py`.
- **Parameterize everything.** Always use `?` placeholders (or the Python sqlite3 parameter style) instead of string interpolation to avoid SQL injection and to reuse prepared statements.
- **Return typed data.** Repositories should normalize JSON/text columns into Python types (lists/dicts) before returning them, and callers should avoid re-parsing the same field. When possible, add `TypedDict`/`Protocol` definitions for result rows to keep `ty` happy.
- **Document migrations.** If a schema change requires backfilling or data transforms, add a note in `backend/core/db/README.md` (or create a migration script under `scripts/`) so other contributors know how to upgrade their local databases.

### Creating Reusable UI Components

When creating timeline or list components with sticky headers:

```typescript
// Use StickyTimelineGroup for date-grouped data
import { StickyTimelineGroup } from '@/components/shared/StickyTimelineGroup'

<StickyTimelineGroup
  items={activities}
  getDate={(activity) => activity.startTimestamp}
  renderItem={(activity) => <ActivityCard activity={activity} />}
  dateCountMap={dateCountMap}  // Optional: pass real DB counts
  emptyMessage={t('activity.noData')}
/>
```

The component handles:
- Automatic date grouping and sorting
- Sticky headers that replace on scroll (CSS sticky positioning)
- i18n date formatting
- Optional real database counts vs loaded item counts

## Project Structure

```
ido/
├── src/                          # React frontend
│   ├── views/                   # Page components
│   ├── components/              # Reusable UI components
│   ├── lib/
│   │   ├── stores/              # Zustand state management
│   │   ├── client/              # Auto-generated PyTauri client
│   │   ├── types/               # TypeScript type definitions
│   │   └── config/              # Frontend config (menu, routes)
│   ├── hooks/                   # React hooks (useTauriEvents, etc.)
│   └── locales/                 # i18n translation files
│
├── backend/                      # Python backend (points to root)
│   ├── handlers/                # API handlers (@api_handler)
│   ├── core/                    # Core systems (coordinator, db, events)
│   ├── models/                  # Pydantic data models
│   ├── processing/              # Processing layer (pipeline, persistence, summarizer)
│   ├── perception/              # Perception layer (keyboard, mouse, screenshots)
│   ├── agents/                  # AI task agents
│   ├── llm/                     # LLM client integration
│   └── config/                  # Backend configuration
│
├── src-tauri/                    # Tauri app
│   ├── python/ido_app/       # PyTauri entry point
│   ├── src/                     # Rust code
│   └── tauri.conf.json          # Tauri config
│
├── scripts/                      # Build and development scripts
│   ├── unix/                    # macOS/Linux scripts
│   ├── windows/                 # Windows PowerShell scripts
│   └── cross-platform/          # Platform-agnostic scripts
│
└── docs/                        # Detailed documentation
    ├── user-guide/              # User documentation
    ├── developers/              # Developer documentation
    │   ├── getting-started/
    │   ├── architecture/        # data-flow.md with actual timing
    │   ├── guides/
    │   └── reference/
    ├── ANALYSIS_SUMMARY.md      # Data flow analysis findings
    └── QUICK_REFERENCE.md       # Quick timing reference card
```

## Important Files

- `backend/core/coordinator.py`: Main orchestrator, runs `_processing_loop()` every 30s
- `backend/processing/pipeline.py`: Event extraction and activity aggregation (separate scheduled tasks)
- `backend/core/events.py`: Tauri event emission system
- `backend/core/sqls/queries.py`: **All SQL queries must be defined here**
- `backend/core/sqls/schema.py`: Database table schemas
- `backend/handlers/__init__.py`: API handler registry, import all handler modules here
- `src-tauri/python/ido_app/__init__.py`: PyTauri entry point, registers commands
- `src/lib/client/`: Auto-generated TypeScript API client (DO NOT EDIT MANUALLY)
- `src/lib/stores/activity.ts`: Activity timeline state (uses polling, not events)
- `src/hooks/useTauriEvents.ts`: Tauri event listener hook
- `src/components/shared/`: Reusable UI components (StickyTimelineGroup, TimeDisplay, etc.)
- `.prettierrc`: Prettier configuration with Tailwind CSS class sorting plugin
- `pyproject.toml`: Python dependencies and build config
- `package.json`: Node.js dependencies and scripts

## Data Models

**Core Types:**
- `RawRecord`: Raw events from perception layer (keyboard, mouse, screenshots)
- `Event`: Extracted from LLM analysis of screenshots (emitted via API calls, not events)
- `Activity`: User-visible activity aggregations (created every 10 minutes by aggregation task)
- `Task`: AI-generated task recommendations (from agents)

All Pydantic models inherit from `backend/models/base.BaseModel` which provides automatic camelCase <-> snake_case conversion for frontend compatibility.

## Common Development Scenarios

### Scenario 1: Frontend-only changes

```bash
pnpm dev  # Fast dev server, no backend changes needed
```

### Scenario 2: Backend + Frontend changes

```bash
pnpm tauri:dev:gen-ts  # Hot reload, auto-generates TS types
```

### Scenario 3: Adding new Python handler

```bash
# 1. Create handler in backend/handlers/my_feature.py with @api_handler
# 2. Import in backend/handlers/__init__.py
# 3. Sync backend
pnpm setup-backend

# 4. Start dev
pnpm tauri:dev:gen-ts

# 5. Use in frontend (types auto-available)
import { apiClient } from '@/lib/client'
await apiClient.myHandler(...)
```

### Scenario 4: Debugging backend API independently

```bash
# Start FastAPI server (same handlers as PyTauri)
uvicorn app:app --reload

# Visit API docs: http://localhost:8000/docs
# Test endpoints in Swagger UI
```

### Scenario 5: Understanding activity latency

Activities don't appear immediately. The flow is:

```
T=0s      User starts working
T=4s      20 screenshots accumulated → LLM extraction (generates Events, not Activities)
T=5s      Events saved to DB
T=10m     Activity aggregation task runs → Activities created from Events
T=10m+30s Frontend polls → fetches new activities
T=10m+31s Activities visible in UI
```

**This is intentional:** Events appear quickly (seconds), activities appear slowly (10+ minutes) as a result of careful aggregation and deduplication.

## System Integration

### LLM Integration

- Backend uses OpenAI-compatible APIs (configured in settings)
- Model configuration stored in SQLite (`llm_models` table)
- Active model must pass test before system can run
- LLM used for: event extraction from screenshots, activity analysis, task generation
- **Trigger:** When 20+ screenshots accumulated (~4 seconds of active work)

#### LLM Usage Statistics

The system tracks detailed LLM usage statistics per model configuration:

- **Database Table:** `llm_token_usage`
- **Tracked Metrics:**
  - `model`: The actual model name returned by the API (e.g., "gpt-4", "qwen3vl_30b_instruct")
  - `model_config_id`: References the specific model configuration in `llm_models` table
  - `prompt_tokens`: Input tokens used
  - `completion_tokens`: Output tokens used
  - `total_tokens`: Total tokens consumed
  - `cost`: Calculated cost based on model pricing
  - `request_type`: Type of request (e.g., "chat", "event_extraction")

- **Statistics Filtering:**
  - Statistics are filtered by `model_config_id`, not model name
  - This allows multiple configurations using the same underlying model to have separate statistics
  - Example: Two configs "qwen1" and "qwen3.1" both using "qwen3vl_30b_instruct" will have separate usage stats
  
- **Cost Calculation:**
  - When viewing "All Models": Uses recorded `cost` from database
  - When viewing specific model: Recalculates cost using model's configured pricing (input_token_price, output_token_price)
  - Ensures accurate cost even if pricing changes after usage

- **Frontend Display:**
  - Dashboard shows: Total tokens, API calls, Total cost, Daily trends (last 7 days)
  - Selecting a specific model filters all statistics to that configuration
  - Model pricing displayed when single model selected

### Database

- SQLite database at `~/.config/ido/ido.db`
- **Key Tables:**
  - `activities`: User activity aggregations
  - `events`: Extracted events from screenshots
  - `tasks`: AI-generated task recommendations
  - `llm_models`: LLM model configurations
  - `llm_token_usage`: LLM usage tracking (with `model_config_id` foreign key)
  - `settings`: Application settings
  - `raw_records`: Raw perception data
- Database operations coordinated by `backend/core/db.py` and `backend/processing/persistence.py`

**Database Migration:**
- When updating from older versions, run migration scripts in `scripts/` directory
- Example: `uv run python scripts/migrate_llm_usage_add_config_id.py` adds `model_config_id` to existing usage records

### System Permissions (macOS)

Requires permissions for:
- Accessibility (keyboard/mouse monitoring)
- Screen Recording (screenshots)
- Handled by `backend/handlers/permissions.py`

### Configuration Parameters

Key parameters affecting behavior:

```python
# Perception layer timing
monitoring.capture_interval = 0.2  # seconds (screenshot frequency)
monitoring.window_size = 60  # seconds (raw record retention)

# Processing layer timing
monitoring.processing_interval = 30  # seconds (main loop frequency)
processing.event_extraction_threshold = 20  # screenshots (LLM trigger)
processing.activity_summary_interval = 600  # seconds (10 minutes)
processing.knowledge_merge_interval = 1200  # seconds (20 minutes)
processing.todo_merge_interval = 1200  # seconds (20 minutes)

# Screenshot deduplication
processing.enable_screenshot_deduplication = True
```

Modifying these values can significantly impact:
- **Activity latency:** Increase `activity_summary_interval` = longer delay before activities appear
- **LLM cost:** Decrease `event_extraction_threshold` = more frequent LLM calls
- **Storage:** Increase `capture_interval` = fewer screenshots, but less granular data
- **CPU:** Decrease `processing_interval` = more frequent processing, higher CPU usage

## Debugging Tips

- **TypeScript client not updating?** Run `pnpm setup-backend`
- **Backend changes not reflected?** Restart `pnpm tauri dev`
- **CamelCase conversion issues?** Ensure models inherit from `backend/models/base.BaseModel`
- **Activity not appearing?** Wait 10+ minutes and check if activity aggregation ran (check logs for `_periodic_activity_summary`)
- **Activity appearing later than expected?** Check `processing.activity_summary_interval` configuration
- **Event not visible?** Note that only certain events emit Tauri notifications; many require polling or manual fetches
- **i18n key mismatch?** Run `pnpm check-i18n`

## Testing

```bash
# Backend tests (if available)
pytest

# Frontend linting
pnpm lint

# i18n validation
pnpm check-i18n
```

## Platform-Specific Notes

### macOS

- Code signing required for distribution: `pnpm tauri:build:signed`
- Uses `pyobjc` for native macOS APIs
- Scripts in `scripts/unix/`

### Windows

- Use PowerShell scripts: `pnpm setup:win`, `pnpm tauri:dev:gen-ts:win`
- Scripts in `scripts/windows/`
- May require execution policy adjustment

### Linux

- Use Unix scripts: `pnpm setup`, `pnpm tauri:dev:gen-ts`
- Requires X11 or Wayland for GUI

## Privacy & Security

- All data processing is local (no cloud uploads)
- Screenshots stored locally with automatic expiration
- LLM calls use user-provided API keys
- Database is local SQLite
- Open source and auditable
- **Important:** All keyboard input is recorded (no filtering at capture time) - document to users

## Further Reading

- **Data Flow Details:** See `docs/developers/architecture/data-flow.md` for complete timing information and event sequences
- **Analysis Summary:** See `docs/ANALYSIS_SUMMARY.md` for implementation findings and configuration impact
- **Quick Reference:** See `docs/QUICK_REFERENCE.md` for quick timing lookups
